# CelebSync: A Wav2Lip-Deepfake <br>
The key idea behind Wav2Lip is to use two neural networks: a visual network and an audio network. The visual network takes as input the target video frames and extracts the facial landmarks and region around the lips. The audio network takes the input speech audio and extracts a spectrogram, which represents the frequency content of the audio over time. <br>
# A project with dual benefits, Deepfake and Lip Syncing
# Task 1: <br>
There is a video capturing my face only. Used to impose the face movements along with the lip movement onto Albert Einstein's image and thereby create a video.<br>
https://github.com/anantmehta33/Wav2Lip-Deepfake/assets/87894541/dea1ddb0-b086-448d-b6a8-45b561029fc6 <br>
![Screenshot (25)](https://github.com/anantmehta33/Wav2Lip-Deepfake/assets/87894541/ad0f427e-1e85-49af-9eaf-424699280394) <br>
![Screenshot (22)](https://github.com/anantmehta33/Wav2Lip-Deepfake/assets/87894541/874aded4-c7b3-42ff-a134-0b996bd0cc6c) <br>
# Task 2: <br>
Imposed an audio clip onto this generated video, to make Einstein speak whatever i want :) <br>
https://github.com/anantmehta33/Wav2Lip-Deepfake/assets/87894541/43124be5-15c0-42f1-a98e-56f75c4865b5 <br>
![Screenshot (27)](https://github.com/anantmehta33/Wav2Lip-Deepfake/assets/87894541/a61dabd5-9482-4411-be6d-851b3d66c6bd)
